{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.svm import *\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.feature_extraction import *\n",
    "from sklearn.naive_bayes import *\n",
    "import xgboost\n",
    "from scipy.sparse import *\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.neural_network import *\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.loadtxt('training_data.txt', skiprows=1)\n",
    "y = data[:,0]\n",
    "X = data[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtest = np.loadtxt('test_data.txt', skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xvecsum = np.sum(X, axis=1)\n",
    "\n",
    "Tfid = text.TfidfTransformer(norm='l2')\n",
    "Tfid.fit(X, y)\n",
    "TfidXsparse = Tfid.transform(X)\n",
    "TfidXtest = Tfid.transform(Xtest)\n",
    "TfidX = np.asarray(csr_matrix.todense(TfidXsparse))\n",
    "temp_arr = []\n",
    "for i in range(0, len(TfidX)):\n",
    "    temp_arr.append(np.append(TfidX[i], Xvecsum[i]))\n",
    "TfidX_sum = np.array(temp_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=100, algorithm='arpack')\n",
    "sv_tfidX = svd.fit_transform(TfidX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binX = []\n",
    "for i in range(0, len(X)):\n",
    "    binX.append(X[i] > 0)\n",
    "binX = np.array(binX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_count = np.sum(X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xvecsum = np.sum(X, axis=1)\n",
    "Xcomb = []\n",
    "\n",
    "for i in range(0, len(X)):\n",
    "    temp_arr = np.concatenate((TfidX[i], sv_tfidX[i]))\n",
    "    temp_arr = np.append(temp_arr, Xvecsum[i])\n",
    "    Xcomb.append(temp_arr)\n",
    "Xcomb = np.array(Xcomb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 1101)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xcomb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X, y)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "slimX = model.transform(X)\n",
    "\n",
    "lsvc = LinearSVC(C=0.05, penalty=\"l1\", dual=False).fit(Xnorm, y)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "slimXnorm = model.transform(Xnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 246)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slimXnorm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_lr(X, y):\n",
    "    lr_clf = LogisticRegressionCV()\n",
    "    lr_clf.fit(X, y)\n",
    "    best_C = lr_clf.C_[0]\n",
    "\n",
    "    lr_clf = LogisticRegression(C=best_C)\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    scores = cross_val_score(lr_clf, X, y, cv=kfold)\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8515996924812308"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_lr(Xnorm, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85089970501560663"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_lr(Xcomb, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear-SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_svmfit(X, y):\n",
    "    svc_params = {'C': np.logspace(-4, 4, 7)}\n",
    "    svc = LinearSVC(dual=False)\n",
    "    search_clf = GridSearchCV(svc, svc_params)\n",
    "    search_clf.fit(X, y)\n",
    "    clf = search_clf.best_estimator_\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    scores = cross_val_score(clf, X, y, cv=kfold)\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84204977965311123"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_svmfit(binX, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85119914267494645"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_svmfit(TfidX, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_baseline(input_N):\n",
    "    def build_fn():\n",
    "        model = Sequential()\n",
    "        model.add(Dense(100, input_dim=input_N, kernel_initializer='normal', activation='relu'))\n",
    "        model.add(Dropout(0.05))\n",
    "        model.add(Dense(30, activation='relu'))\n",
    "        model.add(Dropout(0.05))\n",
    "        model.add(Dense(30, activation='relu'))\n",
    "        model.add(Dropout(0.05))\n",
    "\n",
    "        model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "        # Compile model\n",
    "        model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "        return model\n",
    "    return build_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_NN(X, y):\n",
    "    estimator = KerasClassifier(build_fn=create_baseline(X.shape[1]), epochs=5, batch_size=20, verbose=0)\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    results = cross_val_score(estimator, X, y, cv=kfold)\n",
    "    return results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85044867954880343"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_NN(Xcomb,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boosted trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82295144120009012"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_tree = xgboost.XGBClassifier(max_depth=10, objective='binary:logistic', eta=0.6)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "scores = cross_val_score(xg_tree, TfidX_sum, y, cv=kfold)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boosted linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84674965490935339"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_model = xgboost.XGBClassifier(booster='gblinear', reg_lambda=0, eval_metric='error', alpha=0.1)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "scores = cross_val_score(xg_model, Xcomb, y, cv=kfold)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82809961642497609"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_model = xgboost.XGBClassifier(booster='gblinear', reg_lambda=0, eval_metric='error')\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "scores = cross_val_score(xg_model, sv_tfidX, y, cv=kfold)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgtree = xgboost.XGBClassifier()\n",
    "xgtree.fit(TfidX, y)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "scores = cross_val_score(xgtree, TfidX, y, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80035241990060491"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xg_model = xgboost.XGBClassifier(booster='gblinear', reg_lambda=0, 'objective':'binary:logistic')\n",
    "xg_model.fit(TfidX, y)\n",
    "test_pred = xg_model.predict(TfidXtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_pred_df(test_pred):\n",
    "    preds = []\n",
    "    for pred in test_pred:\n",
    "        preds.append(int(pred))\n",
    "    out_df = pd.DataFrame({'Prediction':preds})\n",
    "    out_df.index += 1\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df = make_pred_df(test_pred)\n",
    "out_df.to_csv('XGlinear_Tfid_01.txt', index_label='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83019890401555652"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_bayes = MultinomialNB(alpha=0.5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "scores = cross_val_score(mn_bayes, TfidX, y, cv=kfold)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81569986570624164"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restricted boltzmann machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble models (not worth it?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1, X2, y1, y2 = train_test_split(X, y, test_size=0.25)\n",
    "partial_Tfid = text.TfidfTransformer()\n",
    "partial_Tfid.fit(X1, y1)\n",
    "tfX1 = partial_Tfid.transform(X1)\n",
    "tfX2 = partial_Tfid.transform(X2)\n",
    "svd = TruncatedSVD(n_components=100, algorithm='arpack')\n",
    "svX1 = svd.fit_transform(tfX1)\n",
    "svX2 = svd.fit_transform(tfX2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2d3eb978>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = Sequential()\n",
    "nn.add(Dense(100, input_dim=tfX1.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "nn.add(Dropout(0.2))\n",
    "nn.add(Dense(30, activation='relu'))\n",
    "nn.add(Dropout(0.2))\n",
    "\n",
    "nn.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "# Compile model\n",
    "nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "nn.fit(tfX1, y1, epochs=10, batch_size=20, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 43us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.63085801222324367, 0.83779999999999999]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.evaluate(tfX2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2e94d5f8>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_notfid = Sequential()\n",
    "nn_notfid.add(Dense(100, input_dim=X1.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "nn_notfid.add(Dropout(0.2))\n",
    "nn_notfid.add(Dense(30, activation='relu'))\n",
    "nn_notfid.add(Dropout(0.2))\n",
    "\n",
    "nn_notfid.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "# Compile model\n",
    "nn_notfid.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "nn_notfid.fit(X1, y1, epochs=10, batch_size=20, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 67us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.81601017638444906, 0.83720000000000006]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_notfid.evaluate(X2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2d3f3e48>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_sv = Sequential()\n",
    "nn_sv.add(Dense(60, input_dim=svX1.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "nn_sv.add(Dropout(0.1))\n",
    "\n",
    "nn_sv.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "# Compile model\n",
    "nn_sv.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "nn_sv.fit(svX1, y1, epochs=10, batch_size=20, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 59us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3100045047760009, 0.49659999999999999]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_sv.evaluate(svX2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_model = xgboost.XGBClassifier()\n",
    "xg_model.fit(svX1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50980000000000003"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_model.score(svX2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_pred = np.round(nn.predict(tfX2))[:,0]\n",
    "nn_notfid_pred = np.round(nn_notfid.predict(X2))[:,0]\n",
    "nn_sv_pred = np.round(nn_sv.predict(sv_tfidX))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_X = [nn_pred, nn_notfid_pred, nn_sv_pred]\n",
    "ens_X = np.array(ens_X).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4924"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y2 == nn_sv_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ens_Xtest = [lr_predtest, nn_predtest, mn_predtest, xglin_predtest, xgtree_predtest, nn_notfid_predtest]\n",
    "ens_Xtest = np.array(ens_Xtest).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = xgtree_ens.predict(ens_Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df = make_pred_df(test_pred)\n",
    "out_df.to_csv('Ensemble_01.txt', index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
