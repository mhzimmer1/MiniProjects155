{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.svm import *\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.feature_extraction import *\n",
    "from sklearn.naive_bayes import *\n",
    "import xgboost\n",
    "from scipy.sparse import *\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.neural_network import *\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from joblib import Parallel, delayed\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.loadtxt('training_data.txt', skiprows=1)\n",
    "y = data[:,0]\n",
    "X = data[:,1:]\n",
    "Xtest = np.loadtxt('test_data.txt', skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_TfidX(X):\n",
    "    Tfid = text.TfidfTransformer(norm='l2')\n",
    "    Tfid.fit(X)\n",
    "    TfidXsparse = Tfid.transform(X)\n",
    "    TfidX = np.asarray(csr_matrix.todense(TfidXsparse))\n",
    "    return TfidX\n",
    "\n",
    "def gen_svX(X):\n",
    "    TfidX = gen_TfidX(X)\n",
    "    svd = TruncatedSVD(n_components=100, algorithm='arpack')\n",
    "    sv_tfidX = svd.fit_transform(TfidX)\n",
    "    return sv_tfidX\n",
    "\n",
    "def gen_combX(X, TfidX, svX):\n",
    "    Xvecsum = np.sum(X, axis=1)\n",
    "    Xcomb = []\n",
    "\n",
    "    for i in range(0, len(X)):\n",
    "        temp_arr = np.concatenate((TfidX[i], svX[i]))\n",
    "        temp_arr = np.append(temp_arr, Xvecsum[i])\n",
    "        Xcomb.append(temp_arr)\n",
    "    Xcomb = np.array(Xcomb)\n",
    "    return Xcomb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_baseline(input_N):\n",
    "    def build_fn():\n",
    "        do = 0.05\n",
    "        model = Sequential()\n",
    "        model.add(Dense(100, input_dim=input_N, kernel_initializer='normal', activation='relu'))\n",
    "        model.add(Dropout(do))\n",
    "        model.add(Dense(30, activation='relu'))\n",
    "        model.add(Dropout(do))\n",
    "        model.add(Dense(30, activation='relu'))\n",
    "        model.add(Dropout(do))\n",
    "        model.add(Dense(30, activation='relu'))\n",
    "        model.add(Dropout(do))\n",
    "\n",
    "\n",
    "        model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "        # Compile model\n",
    "        model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "        return model\n",
    "    return build_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def meta_model_iter(X, y):\n",
    "    X1, X2, y1, y2 = train_test_split(X, y, test_size=0.2)\n",
    "    TfidX1 = gen_TfidX(X1)\n",
    "    svX1 = gen_svX(X1)\n",
    "    combX1 = gen_combX(X1, TfidX1, svX1)\n",
    "    TfidX2 = gen_TfidX(X2)\n",
    "    svX2 = gen_svX(X2)\n",
    "    combX2 = gen_combX(X2, TfidX2, svX2)\n",
    "    \n",
    "    rbf_svm = SVC(C=1.5, gamma=0.015)    \n",
    "    svd_clf = SVC(C=50, gamma=0.2)\n",
    "    pn_svm = SVC(C=0.05, coef0=10, degree=3)\n",
    "    nn = create_baseline(combX1.shape[1])()    \n",
    "    mn_bayes = MultinomialNB(alpha=0.5)\n",
    "    xg_lin = xgboost.XGBClassifier(booster='gblinear', reg_lambda=0, eval_metric='error')\n",
    "    xg_tree = xgboost.XGBClassifier(max_depth=5, objective='binary:logistic', eta=0.6)\n",
    "    \n",
    "    rbf_svm.fit(X1, y1)\n",
    "    svd_clf.fit(svX1, y1)\n",
    "    pn_svm.fit(X1, y1)\n",
    "    nn.fit(combX1, y1, epochs=30, batch_size=20, verbose=False)\n",
    "    mn_bayes.fit(TfidX1, y1)\n",
    "    xg_lin.fit(TfidX1, y1)\n",
    "    xg_tree.fit(TfidX1, y1)\n",
    "    \n",
    "    rbf_svm_pred = rbf_svm.predict(X2)\n",
    "    svd_clf_pred = svd_clf.predict(svX2)\n",
    "    pn_svm_pred = pn_svm.predict(X2)\n",
    "    nn_pred_sig = nn.predict(combX2)\n",
    "    nn_pred = np.round(nn_pred_sig)[:,0]\n",
    "    bayes_pred = mn_bayes.predict(TfidX2)\n",
    "    xg_lin_pred = xg_lin.predict(TfidX2)\n",
    "    xg_tree_pred = xg_tree.predict(TfidX2)\n",
    "    \n",
    "    preds = [rbf_svm_pred, svd_clf_pred, pn_svm_pred, nn_pred, bayes_pred, xg_lin_pred, xg_tree_pred]\n",
    "    preds = np.array(preds)\n",
    "\n",
    "    return preds, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_test_preds(X, y, Xtest):\n",
    "    TfidX = gen_TfidX(X)\n",
    "    svX = gen_svX(X)\n",
    "    combX = gen_combX(X, TfidX, svX)\n",
    "    \n",
    "    svXtest = gen_svX(Xtest)\n",
    "    TfidXtest = gen_TfidX(Xtest)\n",
    "    combXtest = gen_combX(Xtest, TfidXtest, svXtest)\n",
    "    \n",
    "    rbf_svm = SVC(C=1.5, gamma=0.015)    \n",
    "    svd_clf = SVC(C=50, gamma=0.2)\n",
    "    pn_svm = SVC(C=0.05, coef0=10, degree=3)\n",
    "    nn = create_baseline(combX.shape[1])()    \n",
    "    mn_bayes = MultinomialNB(alpha=0.5)\n",
    "    xg_lin = xgboost.XGBClassifier(booster='gblinear', reg_lambda=0, eval_metric='error')\n",
    "    xg_tree = xgboost.XGBClassifier(max_depth=5, objective='binary:logistic', eta=0.6)\n",
    "    \n",
    "    rbf_svm.fit(X, y)\n",
    "    svd_clf.fit(svX, y)\n",
    "    pn_svm.fit(X, y)\n",
    "    nn.fit(combX, y, epochs=30, batch_size=20, verbose=False)\n",
    "    mn_bayes.fit(TfidX, y)\n",
    "    xg_lin.fit(TfidX, y)\n",
    "    xg_tree.fit(TfidX, y)\n",
    "    \n",
    "    rbf_svm_pred = rbf_svm.predict(Xtest)\n",
    "    svd_clf_pred = svd_clf.predict(svXtest)\n",
    "    pn_svm_pred = pn_svm.predict(Xtest)\n",
    "    nn_pred_sig = nn.predict(combXtest)\n",
    "    nn_pred = np.round(nn_pred_sig)[:,0]\n",
    "    bayes_pred = mn_bayes.predict(TfidXtest)\n",
    "    xg_lin_pred = xg_lin.predict(TfidXtest)\n",
    "    xg_tree_pred = xg_tree.predict(TfidXtest)\n",
    "    \n",
    "    preds = [rbf_svm_pred, svd_clf_pred, pn_svm_pred, nn_pred, bayes_pred, xg_lin_pred, xg_tree_pred]\n",
    "    preds = np.array(preds)\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_pred_df(test_pred):\n",
    "    preds = []\n",
    "    for pred in test_pred:\n",
    "        preds.append(int(pred))\n",
    "    out_df = pd.DataFrame({'Prediction':preds})\n",
    "    out_df.index += 1\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_preds = make_test_preds(X, y, Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fi = open('TestEnsemblePreds.dat', 'wb')\n",
    "pickle.dump(test_preds, fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = xgboost.XGBClassifier(max_depth=3, eta=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "b'[11:18:06] src/objective/regression_obj.cc:44: Check failed: preds.size() == info.labels.size() (3 vs. 4000) labels are not correctly providedpreds.size=3, label.size=4000\\n\\nStack trace returned 6 entries:\\n[bt] (0) 0   libxgboost.dylib                    0x0000001a0d43ffc8 _ZN4dmlc15LogMessageFatalD2Ev + 40\\n[bt] (1) 1   libxgboost.dylib                    0x0000001a0d4ad347 _ZN7xgboost3obj10RegLossObjINS0_22LogisticClassificationEE11GetGradientERKNSt3__16vectorIfNS4_9allocatorIfEEEERKNS_8MetaInfoEiPNS5_INS_6detail18bst_gpair_internalIfEENS6_ISG_EEEE + 599\\n[bt] (2) 2   libxgboost.dylib                    0x0000001a0d43c616 _ZN7xgboost11LearnerImpl13UpdateOneIterEiPNS_7DMatrixE + 1014\\n[bt] (3) 3   libxgboost.dylib                    0x0000001a0d4554ef XGBoosterUpdateOneIter + 79\\n[bt] (4) 4   _ctypes.cpython-36m-darwin.so       0x00000001064802c7 ffi_call_unix64 + 79\\n[bt] (5) 5   ???                                 0x00007ffeea53dac0 0x0 + 140732829784768\\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-bffb0c124651>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mrunpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'EnsemblePred_11.dat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mrunpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mlr_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/xgboost-0.7-py3.6.egg/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model)\u001b[0m\n\u001b[1;32m    504\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m                               verbose_eval=verbose, xgb_model=None)\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/xgboost-0.7-py3.6.egg/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/xgboost-0.7-py3.6.egg/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/xgboost-0.7-py3.6.egg/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m--> 898\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m    899\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/xgboost-0.7-py3.6.egg/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: b'[11:18:06] src/objective/regression_obj.cc:44: Check failed: preds.size() == info.labels.size() (3 vs. 4000) labels are not correctly providedpreds.size=3, label.size=4000\\n\\nStack trace returned 6 entries:\\n[bt] (0) 0   libxgboost.dylib                    0x0000001a0d43ffc8 _ZN4dmlc15LogMessageFatalD2Ev + 40\\n[bt] (1) 1   libxgboost.dylib                    0x0000001a0d4ad347 _ZN7xgboost3obj10RegLossObjINS0_22LogisticClassificationEE11GetGradientERKNSt3__16vectorIfNS4_9allocatorIfEEEERKNS_8MetaInfoEiPNS5_INS_6detail18bst_gpair_internalIfEENS6_ISG_EEEE + 599\\n[bt] (2) 2   libxgboost.dylib                    0x0000001a0d43c616 _ZN7xgboost11LearnerImpl13UpdateOneIterEiPNS_7DMatrixE + 1014\\n[bt] (3) 3   libxgboost.dylib                    0x0000001a0d4554ef XGBoosterUpdateOneIter + 79\\n[bt] (4) 4   _ctypes.cpython-36m-darwin.so       0x00000001064802c7 ffi_call_unix64 + 79\\n[bt] (5) 5   ???                                 0x00007ffeea53dac0 0x0 + 140732829784768\\n'"
     ]
    }
   ],
   "source": [
    "lr_preds = []\n",
    "for i in range(0, 41):\n",
    "    fi = open('EnsemblePred_{}.dat'.format(0), 'wb')\n",
    "    runpred, y = pickle.load(open('EnsemblePred_11.dat', 'rb'))\n",
    "    runpred = runpred[:,0:3]\n",
    "    lr.fit(runpred.T, y)\n",
    "    lr_preds.append(lr.predict(test_preds[:,0:3].T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df = make_pred_df(np.median(lr_preds, axis=0))\n",
    "out_df.to_csv('Ens_xg.txt', index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fi = open('EnsemblePred_{}.dat'.format(0), 'wb')\n",
    "pickle.dump(out, fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pickle.load(open('EnsemblePred_11.dat', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.,  1.,  0., ...,  1.,  0.,  1.],\n",
       "        [ 1.,  1.,  1., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "        ..., \n",
       "        [ 0.,  1.,  0., ...,  1.,  0.,  1.],\n",
       "        [ 0.,  1.,  0., ...,  1.,  0.,  1.],\n",
       "        [ 0.,  1.,  0., ...,  1.,  1.,  1.]]),\n",
       " array([ 1.,  1.,  0., ...,  1.,  0.,  1.]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pickle.load(open('EnsemblePred_12.dat', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "        ..., \n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "        [ 1.,  1.,  0., ...,  0.,  0.,  0.]]),\n",
       " array([ 1.,  0.,  0., ...,  0.,  0.,  1.]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
